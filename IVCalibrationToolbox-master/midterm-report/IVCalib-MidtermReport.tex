\documentclass[letterpaper]{article}
\title{
  IVCalib: A Toolbox to Calibrate Between a Camera and an IMU\\
  \Large{16-831 HW3: Fall 2011}
}
\author{Andrew Chambers, Natasha Kholgade, and Marynel V\'azquez}
\date{}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{url}
\usepackage{graphicx}
\usepackage{color}
\usepackage{subfigure}
\usepackage{hyperref}
\newcommand{\bb}[1]{\mathbf{#1}}

\begin{document}

\maketitle

\section{Introduction}

In this project, we estimate the rotation and translation between a rigidly connected camera and IMU using an unscented Kalman filter. Calibrating a camera-IMU setup is the first step in sensor fusion research. We are interested in creating an open-source calibration toolbox that can be used as a starting point by sensor fusion enthusiasts. The unscented Kalman filter helps to propagate the state of our system through process and measurement models that incorporate rotation, which is non-linear.

The state vector in our system consists of the camera-IMU rotation and translation, as well as the orientation and position of the IMU in the world coordinate system, the velocity in world space, the gravity vector, and the biases of the IMU's accelerometer and the gyroscope. The IMU-camera setup moves in the world space, and the camera images a set of world points with known locations in the world space. The imaged points form the measurement in our system. We predict the next state of the system from the current state by propagating a set of sigma points through the process model. We correct the state whenever a measurement is obtained from the camera.

We have performed an initial set of experiments where we assume we know everything about the system except the translation between the camera and the IMU. We estimate the translation using a modified process model for translation alone, and we analyze our performance in the face of noise in the measurement of the imaged points and the velocity.

\section{UKF Formulation}
\label{sec:UKF}

In general, we follow the unscented Kalman filter formulation by Kelly
and Sukhatme \cite{2011:kelly:article}. This section 
summarizes important aspects of the filtering process and some
implementation details.

\subsection{System State}

In our system, we will ultimately estimate the world space position
and orientation of the IMU, $\bb{p}_I^W(t)$ and
${\overline{q}}_I^W(t)$, the velocity of the IMU-camera setup in world
space, $\bb{v}^W$, the biases for the gyroscope and accelerometer,
$\bb{b}_g(t)$ and $\bb{b}_a(t)$, the gravity vector, $\bb{g}^W(t)$,
and, of course, the position and orientation of the camera with
respect to the IMU, $\bb{p}_C^I$ and $\overline{q}_C^I$ (i.e. the
translation and rotation between the devices). The latter two are the
calibration parameters we intend to estimate, and they do not change
over time. The state vector, $\bb{x}_s(t)$ has $26 \times 1$
variables.
\begin{equation}
\bb{x}_t=\begin{bmatrix} (\bb{p}_I^W(t))^T & ({\overline{q}}_I^W(t))^T  & (\bb{v}^W)^T  & (\bb{b}_g(t))^T &  (\bb{b}_a(t))^T & (\bb{g}^W(t))^T  & (\bb{p}_C^I)^T & (\overline{q}_C^I)^T\end{bmatrix}
\label{eq:UKF-state}
\end{equation}

The process model uses IMU measurements as control inputs along the
vein of Kelly and Sukhatme \cite{2011:kelly:article}. We model the accelerometer and
gyroscope biases as Gaussian random walk processes driven by zero mean
noise $\bb{n}_{aw}$ and $\bb{n}_{gw}$, with covariances $\bb{Q}_{aw}$
and $\bb{Q}_{gw}$, and we model their additive noise by zero mean
noise $\bb{n}_g$ and $\bb{n}_a$, with covariances $\bb{Q}_a$ and
$\bb{Q}_g$. The differential equations describing the state evolution
are:
\begin{align}
\dot{\bb{p}}_I^W &=\bb{v}^W \\ 
\dot{\overline{q}}_I^W&=\frac{1}{2}\begin{bmatrix}0 & -(\omega^I)^T \\ \omega^I & -[ \omega^I ]_{\times} \end{bmatrix} \overline{q}_I^W \nonumber\\
\dot{\bb{v}}^W &=\bb{a}^W  \nonumber\\
\dot{\bb{g}}^W &=\bb{0}_{3 \times 1}  \nonumber\\
\dot{\bb{b}}_g&=\bb{n}_{gw}  \nonumber\\
\dot{\bb{b}}_a&=\bb{n}_{aw}  \nonumber\\
\dot{\bb{p}}_C^I&=\bb{0}_{3 \times 1} \nonumber\\
\dot{\overline{q}}_C^I&=\bb{0}_{4 \times 1} \nonumber
\end{align}
The measured acceleration and gravity are given as
\begin{align}
\omega_m&=\omega^I+\bb{b}_g+\bb{n}_g  \\
\bb{a}_m&=\bb{C}^T(\overline{q}_I^W)(\bb{a}^W-\bb{g}^W)+\bb{b}_a+\bb{n}_a \nonumber
\end{align}
The entire process noise mean and covariance are
\begin{align}
\bb{n}=\begin{bmatrix} \bb{n}_{gw} \\ \bb{n}_{aw} \\ \bb{n}_g\\ \bb{n}_a \end{bmatrix}, \bb{Q}=\begin{bmatrix} \bb{Q}_{gw} & & & \\ & \bb{Q}_{aw} & & \\ & & \bb{Q}_g & \\ & & & \bb{Q}_a \end{bmatrix}
\end{align}

During measurement, the camera images the world points,
$\bb{p}_{l_i}^W$ (which in our current system, we assume are
known). To take the world points from the world coordinate system to
the camera's coordinate system $\bb{p}_{l_i}^C$, we apply the rotation
and orientation of the IMU in the world coordinate system, and those
of the camera with respect to the IMU:
\begin{align}
\bb{p}_{l_i}^C=(\bb{C}(\overline{q}_C^I))^T \left((\bb{C}(\overline{q}_I^W))^T \left(\bb{p}_{l_i}^W-\bb{p}_I^W\right) -\bb{p}_C^I \right)
\end{align}
We model the projected points $u_i$ and $v_i$ in the camera's coordinate system with additive measurement noise. 
\begin{align}
\bb{z}_i=\begin{bmatrix} u_i \\ v_i \end{bmatrix}&=\begin{bmatrix} x_i' \\ y_i' \end{bmatrix}+\eta_i \\
\begin{bmatrix} x_i' \\ y_i' \\ 1 \end{bmatrix} & \equiv K\begin{bmatrix} x_i \\ y_i  \\ z_i \end{bmatrix} \nonumber
\end{align}
The noise $\eta$ is modeled as zero mean with a covariance matrix $\bb{R}$.

\subsection{Unscented Kalman Filter equations}

In the unscented Kalman filter, at every time step, a set of sigma
points is estimated by jittering the state at that time step
strategically along significant directions of the augmented covariance
matrix. These significant directions correspond to eigenvectors of the
augmented covariance matrix. The \emph{a priori} predicted state is a
weighted average of the sigma points. When a measurement comes in, the
sigma points are fed to the measurement model to get an estimate of
the measurement, and the estimate of the state and the covariance
matrix is corrected by computing a Kalman gain matrix.

The augmented state and covariance updated from the time instant
$t_{k-1}$ is generated by tacking on the noise mean and covariance to
the original state and covariance matrix:
\begin{align}
\bb{\hat{x}}_a^+(t_{k-1})=\begin{bmatrix}\bb{\hat{x}}^+(t_{k-1}) \\ \bb{0}_{12 \times 1}\end{bmatrix}, \bb{P}_a^+(t_{k-1})=\begin{bmatrix} \bb{P}^+(t_{k-1}) & \\  & \bb{Q} \end{bmatrix}
\end{align}
The $N$ sigma points consist of the augmented state at $t_{k-1}$ and
the state jittered positively and negatively along the columns of the
matrix $\bb{S}$ found by the Cholesky decomposition of the augmented
covariance matrix.
\begin{align}
\bb{S} &=\sqrt{(\lambda+N) \bb{P}_a^+(t_{k-1})} \\
^0\chi_a(t_{k-1})&=\bb{\hat{x}}_a^+(t_{k-1}) \nonumber\\
^l\chi_a(t_{k-1})&=\bb{\hat{x}}_a^+(t_{k-1}) + ^l\bb{S}(t_{k-1}), l={1,...,N} \nonumber\\
^{2N+l}\chi_a(t_{k-1})&=\bb{\hat{x}}_a^+(t_{k-1})- ^l\bb{S}(t_{k-1}), l={1,...,N} \nonumber
\label{eq_sigmapoints}
\end{align}
Here $\lambda$ is a constant specified as
$\lambda=\alpha^2(N+\beta)-N$, $\alpha$ is a small number (we use
$\alpha=.1$), and $\beta=2$. Weights are computed for the sigma points
as:
\begin{align}
^0W_m&=\frac{\lambda}{\lambda+N} \\
^0W_c&=\frac{\lambda}{\lambda+N}+\left(1-\alpha^2+\beta\right) \nonumber\\
^jW_m&=^jW_c=\frac{1}{2(\lambda+N)} \nonumber
\end{align}
The sigma points are propagated through the process model, and the
\emph{a priori} estimate of the state and covariance matrix is
calculated using the propagated sigma points and the weights.
\begin{align}
^i\chi_a(t_k)&=\bb{f}(^i\chi_a(t_{k-1})), i=0,...,2N \\
\bb{\hat{x}}^-(t_k)&=\sum_{i=0}^{2N} \text{} ^iW_m \text{}^i\chi(t_k) \nonumber\\
\bb{P}^-(t_k)&=\sum_{i=0}^{2N} \text{} ^iW_c \left( ^i\chi(t_k)-\bb{\hat{x}}^-(t_k)\right) \left( ^i\chi(t_k)-\bb{\hat{x}}^-(t_k)\right)^T \nonumber
\end{align}

When measurement arrives from the camera, the sigma points are
propagated through the measurement model to get an estimate of the
measurement $\bb{\hat{z}}(t_k)$
\begin{align}
^i \gamma(t_k) &= \bb{h}(^i \chi(t_k)), i=0,...,2N \\
\bb{\hat{z}}(t_k) &=\sum_{i=0}^{2N} \text{} ^iW_m ^i\gamma(t_k) \nonumber
\end{align}
The Kalman gain matrix is computed and used to compute the \emph{a
  posteriori} state and covariance matrix.
\begin{align}
\bb{P}_{\bb{\hat{x}\hat{z}}}(t_k)&=\sum_{i=0}^{2N} \text{} ^iW_c\left( ^i \chi(t_k) - \bb{\hat{x}}^-(t_k) \right) \left( ^i \gamma(t_k)- \bb{\hat{z}}(t_k) \right)^T \\
\bb{P}_{\bb{\hat{z}\hat{z}}}(t_k)&=\sum_{i=0}^{2N} \text{} ^iW_c\left( ^i \gamma(t_k) - \bb{\hat{z}}^(t_k) \right) \left( ^i \gamma(t_k)- \bb{\hat{z}}(t_k) \right)^T \nonumber \\
\bb{K}(t_k)&=\bb{P}_{\bb{\hat{x}\hat{z}}}(t_k) \left( \bb{P}_{\bb{\hat{z}\hat{z}}}(t_k) + \bb{R} \right)^{-1} \nonumber \\
\bb{\hat{x}}^+(t_k)&=\bb{\hat{x}}^-(t_k)+\bb{K}(t_k)\left( \bb{z}(t_k)-\bb{\hat{z}}(t_k) \right) \nonumber \\
\bb{P}^+(t_k)&=\bb{P}^-(t_k)-\bb{K}(t_k)\bb{P}_{\bb{\hat{z}\hat{z}}}(t_k)(\bb{K}(t_k))^T \nonumber
\end{align}
\textbf{Note:} As described in Kelly and Sukhatme \cite{2011:kelly:article}, the unscented
Kalman filter updates the state by computing the barycentric mean of
the sigma points. In general the barycentric mean of unit quaternions
$\overline{q}_I^W$ and $\overline{q}_C^I$ will not lie on the unit
sphere, and we require a different parametrization for their
update. We will use the modified Rodrigues parameters (MRPs) of the
error quaternions used in \cite{2011:kelly:article}. The modified Rodrigues
parameter $\delta \bb{e}$ is given as:
\begin{align}
\delta \bb{e}=\frac{\delta \bb{q}}{1+\delta q_0},
\end{align}
where $\delta \bb{q}$ and $\delta q_0$ are each the vector and scalar
portion of the error quaternion. At time step $t_k$, we start off with
a mean error quaternion of $^0\delta
\bb{\hat{e}}_I^W(t_{k-1})=\bb{0}_{3 \times 1}$ and $^0\delta
\bb{\hat{e}}_C^I=\bb{0}_{3 \times 1}$. The MRP part of the sigma
points is computed $^j \bb{\hat{e}}_I^W(t_{k-1})$ in terms of these
mean MRPs using \ref{eq_sigmapoints}, and corresponding quaternions
are propagated as
\begin{align}
^j \hat{\overline{q}}_I^W(t_{k-1})=^j \delta \hat{\overline{q}}_I^W(t_{k-1}) \otimes \hat{\overline{q}}^{W+} (t_{k-1})
\end{align}
The sigma points are passed through the process model, and before
computing the barycentric mean, the mean quaternion is divided out to
get the error quaternion at $t_k$.
\begin{align}
^j \delta \hat{\overline{q}}_I^W(t_k)=^j \hat{\overline{q}}_I^W(t_k) \otimes \left( ^0 \hat{\overline{q}}_I^W(t_k)\right)^{-1}
\end{align}
The process of multiplying error vectors to get unit quaternions is
repeated before passing the sigma points to the measurement model, and
they are re-computed before obtaining the Kalman gain matrix. For the
IMU-camera orientation $\overline{q}_C^I$, the error quaternions are
used only when a measurement comes in.

\section{Tests}

We decided to implement the filter progressively given the complexity
of the state space. We considered a reduced number of unknowns and a
very simple model at the beginning. The following subsections detail
our progress towards a complete toolbox for sensor-to-sensor
calibration.

\subsection{Estimating rigid body translation}

\begin{figure}[h!tbp]
\centering
\includegraphics[width=0.5\linewidth]{uniform_points}
\caption{Automatically generated landmarks (red points) in our simulated
  world. The blue line depicts the uniform velocity path used for the
  rigid body translation test.}
\label{fig:TranslationTest-uniformPoints}
\end{figure}


Our first filter implementation consists of estimating the
position in 3D space of the rigid body sensor suite. We assume that we have a "world velocity sensor," which provided noisy estimates of the system's velocity in the world frame. No bias or gravity terms needed to be considered in this model.

We generated a ground truth path for the sensor suite using a simple motion simulator which generates motions from a vector of constant angular velocity and constant acceleration. These motions determine the grouth truth for world velocity, position, and orientation of the sensors at every point in time. We corrupt the grouth truth velocity and provide it to the filter as a sensor measurement at the correction step.
Our state vector has a dimensionality of $3$ in this test,
instead of $26$ as in (\ref{eq:UKF-state}). The process noise
covariance is a $3 \times 3$ diagonal matrix.
\begin{equation}
\bb{x}_t=\begin{bmatrix} p_{I_x}^W(t) & p_{I_y}^W(t) & p_{I_z}^W(t) \end{bmatrix} 
\hspace{4em}
Q = \begin{bmatrix} 
\sigma_x^2 & 0 & 0\\ 
0 & \sigma_y^2 & 0\\ 
0 & 0 & \sigma_z^2
\end{bmatrix} 
\label{eq:TranslationTest-stateVec}
\end{equation}

We automatically generate landmarks by uniformly scattering 3D points
in our simulated world, and projected them into our simulated camera
sensor. Figure \ref{fig:TranslationTest-uniformPoints} depicts a
possible distribution of landmarks in our simulated world. When landmarks are projected into the camera frame and measured as pixel coordinates, we add indepedant Gaussian noise to the pixel coordinates to simulate the real-world behavior of cameras.

\begin{figure}[h!tbp]
\centering
\includegraphics[width=0.85\linewidth]{estimated_position_and_error}
\caption{Estimated 3D world position of the camera and IMU from the UKF and squared error distance between estimated position and grouth truth}
\label{fig:TranslationTest-estimatedPosition}
\end{figure}

Fig. {\ref{fig:TranslationTest-estimatedPosition}} shows the 3D position estimate for the IMU in the world frame from the unscented Kalman filter. We also plot the squared distance between the ground truth and the estimated position at each step in time. There is a large initial error because we initialize the UKF with an error of 0.5 meters in each axis. Even with this large initial error, the filter is able to converge and track the true position.

% TODO. Might be a good idea to regenerate this picture with whatever
% point distribution we used before submitting the report..

\section{Future work}
The next step in the project will be to expand our filter to estimate the full state vector. The most difficult part of this implementation will be the quaternion predication and correction steps within the Kalman filter. We are also developing a more complicated motion simulator to simulate the motion and field of view for a realistic camera-IMU system.


\bibliographystyle{plain}
\bibliography{IVCalib-MidtermReport}

\end{document}

